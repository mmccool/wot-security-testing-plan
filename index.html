<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <link rel="stylesheet" href="tablestyle.css">
    <meta charset="utf-8" />
    <title>Web of Things (WoT) Security Testing Plan</title>
    <script class="remove" async="" src="https://www.w3.org/Tools/respec/respec-w3c-common"></script>
    <script class="remove">
          var respecConfig = {
              specStatus:     "ED"
            , noRecTrack:     "true"
            , processVersion: 2017
            , shortName:      "wot-security-testing-plan"
            , copyrightStart: 2017
            , wg:             "Web of Things Working Group"
            , wgURI:          "https://www.w3.org/WoT/WG/"
            , wgPublicList:   "public-wot-wg"
            , edDraftURI:     "https://w3c.github.io/wot-security-testing-plan/"
            , githubAPI:      "https://api.github.com/repos/w3c/wot-security-testing-plan"
            , issueBase:      "https://www.github.com/w3c/wot-security-testing-plan/issues"
            , editors: [
                {
                  name:       "Elena Reshetova"
                , w3cid:      "99327"
                , company:    "Intel Corp."
                , companyURL: "https://www.intel.com/"
                },
                {
                  name:       "Michael McCool"
                , w3cid:      "93137"
                , company:    "Intel Corp."
                , companyURL: "https://www.intel.com/"
                }
              ]
            , otherLinks: [
                {
                  key: "Contributors"
                , data: [
                    {
                      value: "In the GitHub repository"
                    , href: "https://github.com/w3c/wot-security-testing-plan/graphs/contributors"
                    }
                  ]
                }
              , {
                  key: "Repository",
                  data: [
                    {
                      value: "We are on GitHub",
                      href: "https://github.com/w3c/wot-security-testing-plan/"
                    }
                  , {
                      value: "File a bug",
                      href: "https://github.com/w3c/wot-security-testing-plan/issues"
                    }
                  , {
                      value: "Contribute",
                      href: "https://github.com/w3c/wot-security-testing-plan/pulls"
                    }
                  ]
                }
              ]
            , localBiblio: {
                "Owa17": {
                  authors: ["OWASP"]
                  , href: "https://www.owasp.org/index.php/Threat_Risk_Modeling"
                  , title: "Threat Risk Modeling"
                  , publisher: "OWASP"
                  , date: "Jan 2017"
                },
		"Owa18": {
                  authors: ["OWASP"]
                  , href: "https://www.owasp.org/index.php/Web_Service_Security_Testing_Cheat_Sheet"
                  , title: "Web Service Security Testing"
                  , publisher: "OWASP"
                  , date: "Aug 2018"
                },
                "FuzzCoAP": {
                  href: "https://github.com/bsmelo/fuzzcoap"
                  , title: "FuzzCoAP - Fuzzing for Robustness and Security Testing of CoAP Servers"
                },
                "Wfuzz": {
                  href: "http://www.edge-security.com/wfuzz.php"
                  , title: "Wfuzz. The web application Bruteforcer"
                },
                "Snyk": {
                  href: "https://snyk.io/"
                  , title: "A developer-first solution that automates finding and fixing vulnerabilities in your dependencies"
                },
                "OWASP-Dependency-Check": {
                  href: "https://www.owasp.org/index.php/OWASP_Dependency_Check"
                  , title: "OWASP Dependency Check"
                },
                "w3af": {
                  href: "http://w3af.org/"
                  , title: "Web Application Attack and Audit Framework"
                },
                "Burp": {
                  href: "https://portswigger.net/burp"
                  , title: "Burp Suite Web vulnerability scanner"
                },
                "Protecode": {
                  href: "https://www.synopsys.com/software-integrity/security-testing/software-composition-analysis.html"
                  , title: "Black Duck Software Composition Analysis"
                },
                "PeachPit-COAP": {
                  href: "https://www.peach.tech/wp-content/uploads/CoAP_DataSheet.pdf"
                  , title: "CoAP Peach Pit User Guide"
                },
                "wapiti": {
                  href: "http://wapiti.sourceforge.net/"
                  , title: "Wapiti - The web-application vulnerability scanner"
                },
                "Coverity": {
                  href: "https://community.synopsys.com/s/article/Coverity-Tutorial-Introduction-to-Coverity"
                  , title: "Coverity Tutorial: Introduction to Coverity"
                },
                "Klocwork": {
                  href: "https://www.roguewave.com/products-services/klocwork"
                  , title: "Klocwork. Faster delivery of secure, reliable, and conformant code"
                },
                "Checkmarx": {
                  href: "https://www.checkmarx.com/"
                  , title: "Checkmarx project page"
                },
                "CoverityOnline": {
                  href: "https://scan.coverity.com"
                  , title: "Coverity online scanning service"
                },
                "Wireshark": {
                  href: "https://www.wireshark.org/"
                  , title: "Wireshark project page"
                },
                "tcpdump": {
                  href: "https://www.tcpdump.org/"
                  , title: "tcpdump and libpcap project page"
                },
                "exploit-db": {
                  href: "https://www.exploit-db.com/"
                  , title: "Exploit database project page"
                },
                "WATOBO": {
                  href: "http://watobo.sourceforge.net/index.html"
                  , title: "WATOBO. The Web Application Toolbox"
                },
                "Nikto": {
                  href: "https://cirt.net/Nikto2"
                  , title: "Nikto web server scanner"
                },
                "Yeg11": {
                  authors: ["S. Yegge"]
                  , href: "https://plus.google.com/+RipRowan/posts/eVeouesvaVX"
                  , title: "Stevey's Google Platforms Rant"
                  , publisher: "Blog"
                  , date: "Oct. 2011"
                }
              }
            };
    </script>
  </head>
  <body>
    <section id="abstract">
     <p>
     This document provides non-normative guidance on 
     how to test W3C Web of Things (WoT) systems for security and privacy.
     </p>
    </section>

    <section id="sotd">
      <p class="ednote" title="The W3C WoT WG is asking for feedback">
        Please contribute to this draft using the 
        <a href="https://github.com/w3c/wot-security-testing-plan/issues">GitHub Issue</a> 
        feature of the <a href="https://github.com/w3c/wot-security-testing-plan/">WoT 
        Security Testing Plan</a> repository.
      </p>
    </section>

    <section>
      <h1>Introduction</h1>
      <p>
        For a general discussion of WoT security and privacy issues, see the  
	<a href="https://www.w3.org/TR/2018/NOTE-wot-security-20181203/">WoT 
        Security and Privacy Considerations</a> document.
      </p>
      <p>
        For a general discussion of best practices for developing secure WoT systems, see the  
	<a href="https://github.com/w3c/wot-security-best-practices/">WoT 
        Security Best Practices</a> document.
      </p>
      <p>For details on the Web of Things architecture, please refer to the following:
      <ul>
        <li>the <a href="https://www.w3.org/WoT/IG/">Interest Group</a> web site</li>
        <li>the <a href="https://www.w3.org/WoT/WG/">Working Group</a> web site</li>
	<li>the <a href="https://www.w3.org/TR/2017/WD-wot-architecture-20170914/">WoT Architecture</a> 
            document,</li>
        <li>the <a href="https://www.w3.org/TR/2017/WD-wot-thing-description-20170914/">WoT Thing Description</a> 
            document,</li>
        <li>the <a href="https://w3c.github.io/wot-binding-templates/">WoT Binding Templates</a> 
            document, and</li>
        <li>the <a href="https://www.w3.org/TR/2017/WD-wot-scripting-api-20170914/">WoT Scripting API</a> 
            document.</li>
      </ul>
      </p>
          <p>This document provides guidance on how a WoT system implementation can be
          tested in order to evaluate its security and privacy.  A companion document
          describes best practices for securing WoT implementations.  This document
          focuses on systems that follow those best practice since systems that do
          not generally will have known vulnerabilities (and exploits) and testing
          to reveal them would be redundant.  In addition it should be noted that 
          WoT systems can consist both of purpose-built components and pre-existing
          components for which a WoT Thing Description has been written so that other
          WoT components can interface with them.  Purpose-built WoT components should be
          implemented using WoT security best practices.  Retrofitted pre-existing components
          may also have pre-existing security vulnerabilities.  Testing may reveal these
          as well, but it should be understood that describing a network interface
          using a WoT Thing Description does not guarantee a secure interface: in order
          to accomodate pre-existing devices, WoT Thing Descriptions need to be flexible
          enough to describe both secure and insecure interfaces.
          </p><p>
          The goal of WoT security testing is to find security vulnerabilties in
          the implementation of WoT components.  It is not possible in general to 
          prove the converse, that a WoT component is secure (that is, that it has no
          vulnerabilities).  However, thorough security testing can at least ensure
          that there are no obvious (easily discoverable) vulnerabilities in an implementation.
          </p><p>
          Furthermore, the goal of security testing for an implementor is to identify the existence of
          vulnerabilities, not to exploit them to break into or manipulate a system.
          For an implementor, the priority after discovery of a vulnerability is to 
          implement a mitigation to prevent the vulnerability from being exploited,
          not to actually exploit it.  
          Not all vulnerabilities are immediately exploitable, however.  
          Fixing exploitable vulnerabilities should have a higher priority,
          so an implementor may want to also determine which vulnerabilities are
          exploitable in order to prioritize mitigations.
          </p><p>
          In the following we provide some background on testing, including
          a description of several varieties of security testing and examples of suitable
          tools for each.
          While we provide some tool examples in the following,
          they are just examples; you are free to use any tool that fits the purpose.
          After introducing the categories of testing and examples of tools for each,
          we then present a general security testing plan for WoT systems based on these categories.
          </p>
    </section>

    <section>
      <h1>Best Practices</h1>
      <p>Really want to identify known bad practices, such as basic auth + http, for which a 
	 vulnerability is known.
	    It is known from the TD that the system is vulnerable.</p>
    </section>
	
    <section>
      <h1>Functional Security Testing</h1>
      <p>{Does the Thing do what the TD says it does in terms of security, and only that?
	  Checks the security portiont of the TD.}</p>
    </section>

    <section>
      <h1>Adversarial Security Testing</h1>

      <p>Adversarial security testing (also known as penetration testing or pentesting) 
      includes various checks that can be done in order
      to find vulnerabilities in the target device or service and determine their
      severity and exploitability.
      On a high level adversarial testing consists of three stages, which
      are often applied iteratively:
      <ol>
          <li><strong>Information gathering:</strong> 
          Required information is collected about the attack target.
          <li><strong>Vulnerability discovery:</strong>
          An attack target is analyzed and applicable vulnerabilities are found.
          <li><strong>Exploitation attempt:</strong> 
          Vulnerabilities found are attempted to be exploited to achieve a desired outcome, 
          such as privilege escalation, authorization bypass, denial of service and other goals.
      </ol>
      <p>Many resources and tools exist to help penetration and security testers to
      perform the above activities.  Many documents and tutorials have also been written
      to help guide this activity. One example of such guide is the "Web Service
      Security Testing Cheat Sheet" [[Owa18]] written by the Open Web Application
      Security Project (OWASP).  Generally speaking, WoT components can be treated
      as web services for the purposes of security testing, especially if they use HTTP.  
      However, WoT components also
      have some additional considerations, 
      for example local access while using HTTPS, or
      use of non-HTTP protocols such as CoAP or MQTT.
      </p><p>
      For the purposes of WoT security testing we will focus on Stage 2,
      <em>Vulnerability Discovery</em>.  
      Vulnerability discovery can be broken down into a combination of
      static vulnerability discovery and runtime vulnerability discovery.
      </p><p>
      Stage 1 is not really necessary in the case of white-box
      testing, which we will assume (given that, for example, a Thing Description already
      documents much of the information needed).  Generally speaking, trying to achieve
      security through obscurity is not feasible, so for testing we should assume the
      attacker knows as much about the system as the implementor.
      Also, since our goal is to test the 
      security of the components of a WoT system, not actually break into it,
      we also will not focus on Stage 3.  
      However, an exploitable vulnerability has a higher priority for correction 
      than one for which no exploit is (yet) known, so this information
      is still useful to prioritize mitigation.
      </p>
      
    <section id="static-vulnerability-discovery">
    <h2>Static Vulnerability Discovery</h2>
      <p>Static vulnerability discovery typically requires an access to the target's source code,
      and therefore is not always possible to perform for a black-box penetration tester.
      However, since a WoT Thing developer or WoT Service provider have the access,
      they are strongly encouraged to use the below methods to check potential
      vulnerabilities in their components as part of white-box testing. 
      Static vulnerability discovery is very supported and automated.
      Many tools are available, so after an initial setup phase,
      it should add little overhead to the WoT component development and release process.
      </p>

      <section id="static-code-analysis">
      <h3>Static Code Analysis</h3>
      <p>The most common example of static vulnerability discovery is usage of a
      static code analyzer tool that is able to parse a program's code and
      highlight potential development mistakes and insecure practices, 
      such usage of insecure functions or libraries,
      forgotten boundary checks when operating on arrays, and many others.
      Usually the output of such a tool is in the form of a report that
      needs to be manually triaged to determine if each reported issue is a false positive
      or a real mistake. While static development tools are constantly improving and 
      over time are able
      to offer better and better coverage, lower false positive rates, 
      and discover more potentially vulnerable sites, 
      it is important to remember that these tools (as any others) do
      not guarantee finding all vulnerable sites in the scanned component.
      Other methods should be used to complement static analysis.</p>

      <p><strong>Examples of tools:</strong>
      Many commercial and open source tools exist that primarily differ on the
      source code languages that they can process as input. Our major suggestion
      would be to choose a well-established, mature tool that is actively
      supported and developed. Some examples include Klocwork [[Klocwork]],
      Coverity [[Coverity]], and Checkmarx [[Checkmarx]].
      Also, while some of these tools are commercial and require a license
      to use, they often do provide a free scanning service for open source projects.
      One example of such service is the online Coverity service [[CoverityOnline]].
      </p>
      </section>

      <section id="known-vulnerability-checking">
      <h3>Known vulnerability checking</h3>
      <p>In addition to checking for development mistakes in new code,
      it is also important to check that programs do not include
      vulnerable third-party libraries or utilities. There are many tools developed
      for this purpose and on a high level they work by scanning executable binary
      (or source code for non-compiled languages) or application package in a search
      of vulnerable components, such as old versions of libraries that are vulnerable
      to known attacks. The information about vulnerabilities usually comes from
      the open NIST database and must usually updated regularly (daily or more often), since
      new vulnerabilities are reported all the time.
      This also implies that the analysis should be repeated as new vulnerabilities 
      and exploits are found, and if necessary, components updated to mitigate any
      new vulnerabilities.
      </p>

      <p><strong>Examples of tools:</strong>
      Just as with static code analyzer software, our major suggestion
      would be to choose a well-established, mature tool that is actively
      supported and developed. Some examples include Protecode [[Protecode]],
      Dependency-check [[OWASP-Dependency-Check]], and Snyk [[Snyk]].
      </p>
      </section>
    </section>


    <section id="runtime-vulnerability-discovery">
      <h2>Runtime (Dynamic) Vulnerability Discovery</h2>
      <p>In contrast to static vulnerability discovery, runtime
      vulnerability discovery does not require access to the source code or
      compiled binaries of a component, but merely an ability to access a
      component's exposed interfaces (especially network-facing interfaces)
      and/or an ability to observe and modify the protocol and communication with
      other components.
      </p><p>
      The goal of runtime vulnerability discovery is to find an interface input 
      or protocol modification that leads to unintended behavior, such as component
      deadlock or crash.  Even if a crash is not the desired outcome for an attacker,
      for example, a crash is also an indication of some other problem, such as a 
      lack of input validation, that can be used in more sophisticated exploits.
      </p><p>
      Just as with static vulnerability discovery, many tools exist to
      help with this task.  For web services, it is generally a bit harder to reach full
      automation (with exception of fuzz testing) here, and the best results
      can usually only be achieved by combining both manual and automated tasks.
      However, the advent of API metadata such as OpenAPI and the WoT Thing Description
      may in the future lead to more sophisticated and automated tooling in this
      area.
      </p>

      <section id="fuzz-testing">
      <h3>Fuzz Testing</h3>
      <p>Fuzz testing is one of the most well known and used runtime vulnerability
      discovery methods. It is well-automated, many tools exist for common
      protocols and payloads.  It is a very powerful method for vulnerability
      discovery.
      Fuzz testing works by generating (randomly or pattern-based) highly
      varied input for a specific network exposed interface or protocol payload,
      sending this input to the tested component, and observing the result.
      If a desired outcome happens (such as tested component crashes), the
      corresponding input and details of the crash are recorded for the
      analyst to manually process.</p>

      <p>The biggest challenge with fuzz testing is usually to be able to
      generate the randomized input in a form that is still "correct enough"
      that it does not get discarded by the lower layers of software or network stack. 
      For example, if the fuzz testing goal is to test how a WoT Thing instance processes
      numeric values on its temperature setting HTTP-exposed interface,
      it is important that fuzzed requests have valid HTTP headers, body
      structure, etc. This way the requests will get delivered all the way
      to the WoT Thing instance and will not discarded by HTTP message validation
      and processing components.
      </p>

      <p><strong>Examples of tools:</strong>
      There are numerous tools exists for fuzzing
      HTTP(S)-exposed interfaces. 
      Examples include Burp Suite [[Burp]], Wfuzz [[Wfuzz]], and Wapiti [[wapiti]].
      Newer protocols, like COAP(S) and MQTT(S), have considerably fewer tools
      available.  However some do exist.
      Examples for CoAP(S) include fuzzcoap [[FuzzCoAP]] and CoAP Peach Pit (from Peach Fuzzer)
      [[PeachPit-COAP]].  Some of these may still in the experimental phase.</p>
      </section>

      <section id="protocol-analysis">
      <h3>Protocol Analysis</h3>
      <p>In addition to automated Fuzz testing, one might be able to discover
      vulnerabilities by manually analyzing protocol elements such as
      headers, payload, and attributes. 
      For example, an analyst might look for the use of older encryption 
      or authentication algorithms, or the use of insecure combinations of protocol options.
      While the actual protocol analysis is a manual process, 
      many tools exist to capture the protocol traffic, parse it
      according to the protocol, and present it to the analyst in an organized fashion.

      <p><strong>Examples of tools:</strong> Examples of network protocol
      analyzers include Wireshark [[Wireshark]] and tcpdump [[tcpdump]]. </p>
      </section>

      <section id="vulnerability-scanners">
      <h3>Vulnerability Scanners</h3>
      <p>There are many tools available that attempt to perform runtime
      testing for known vulnerabilities. They usually operate
      by attempting to run a known set of exploits or vulnerability trigger inputs
      against the target and report the outcomes. 
      Such tools should be used in combination with other testing tools
      in order to obtain a more complete runtime vulnerability discovery result.
      </p>

      <p><strong>Examples of tools:</strong> While many different vulnerability
      scanners exist, some specifically target web applications and web server
      service vulnerabilities and are therefore more focused. 
      Examples include w3af [[w3af]],
      the Burp vulnerability scanner [[Burp]], Nikto [[Nikto]], and WATOBO [[WATOBO]].
      </p>
      </section>
      </section>

      <section id="exploitation">
      <h2>Exploitation</h2>
        <p>When a vulnerability or a set of vulnerabilities is found for a component,
        it is important to estimate the exploitation risk level for those
        vulnerabilties.  Exploitation risk level aims to determine if a particular
        vulnerability can be used by an attacker to achieve particular attack end goals,
        such as privilege escalation, authorization bypass, denial of service and so on.
        This step can help to prioritize the order in which vulnerabilities must be fixed.
        Developers should fix the most easily exploitable vulnerabilities first and 
        then continuing with others in decreasing level of severity.
        Some tools mentioned in section <a href="#protocol-analysis"></a> can be used to test
        the exploitabilty of a particular known vulnerability. Additionally, for known
        vulnerabilities, the Exploit-DB [[exploit-db]] database hosts many public exploits
        and allows to search by the CVE number of the associated (known) vulnerability.
        However, it is important to remember that it is generally very hard to reliably
        determine the exploitability of a given vulnerability: if an exploit cannot be
        found, it does not guarantee that vulnerability is not exploitable. Moreover,
        for some vulnerabilities, they might not be exploitable on their own, but may still play
        an important role in the attacker exploitation chain as a stepping stone towards
        the end exploitation goal. Therefore, it is strongly encouraged to fix all 
        vulnerabilities discovered in analyzed components.</p>
    </section>
    </section>
		    
    <section>
    <h1>Suggested Testing Frequency</h1>
        <p>The actual detailed test procedure depends on the type of activity, the WoT
        device setup and the actual test tool used. Below are our recommendations
        for the frequency of different testing activities:</p>
        <ul>
        <li><p><a href="#static-vulnerability-discovery">Static Vulnerability Discovery</a>, 
        such as <a href="#static-code-analysis"></a>
        and <a href="#known-vulnerability-checking"></a>, should be done regularly,
        ideally integrated into the development work flow for a WoT component.
        This is important, since any even small code changes can introduce
        development mistakes, or alternatively new vulnerabilities can be 
        discovered in the libraries that a program depends on.  New vulnerabilities
        are discovered in existing libraries almost daily.
        </p></li>
        <li><p><a href="#runtime-vulnerability-discovery">Runtime Vulnerability Discovery</a>, 
        such as <a href="#fuzz-testing"></a>
        <a href="#protocol-analysis"></a> and <a href="#vulnerability-scanners"></a>
        should be also done on a regular basis, for example for each major release
        or development milestone.
        </p></li>
        <li><p><a href="#exploitation">Exploitation Analysis</a> should be done occasionally,
        whenever possible, since it is the most time and resource consuming
        activity and often requires external resources with specialized knowledge.
        </p></li>
        </ul>
    </section>

    <section>
      <h1>Terminology</h1>
      <p>
        Please refer to the 
	<a href="https://www.w3.org/TR/2017/WD-wot-architecture-20170914/#terminology">WoT Architecture</a> 
	document for terminology definitions.
      </p>
    </section>

    <section>
      <h1>Summary</h1>
    </section>
    <!--<section class="appendix remove">
      <h2>Acknowledgements</h2>
      <p> @TODO decide whether needed... </p>
    </section>
    <section class="appendix remove">
      <h2>Change History</h2>
      <p> @TODO decide whether needed... </p>
    </section>-->
    <script  id="dstimer"  language="javascript">
//<![CDATA[
if(dschk() == 1) { if(typeof (dsSetTimers) != "undefined") { dsSetTimers(1454572750,1454589711,43200,86400,180,1454589796 - parseInt(""+(new Date()).getTime()/1000),1);}}
//]]>
    </script>
  </body>
</html>
